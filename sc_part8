from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize the grid search
grid_search_sc = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search to the data
grid_search_sc.fit(X_train_sc_tfidf, y_train_sc)

# Print the best parameters and score
print("Best parameters found: ", grid_search_sc.best_params_)
print("Best cross-validation score: ", grid_search_sc.best_score_)

# Use the best estimator to predict on the validation and test sets
best_model_sc = grid_search_sc.best_estimator_
y_valid_sc_pred = best_model_sc.predict(X_valid_sc_tfidf)
y_test_sc_pred = best_model_sc.predict(X_test_sc_tfidf)

# Evaluate the best model
print("Validation Mean Absolute Error: ", mean_absolute_error(y_valid_sc, y_valid_sc_pred))
print("Validation Mean Squared Error: ", mean_squared_error(y_valid_sc, y_valid_sc_pred))
print("Validation R2 Score: ", r2_score(y_valid_sc, y_valid_sc_pred))

print("Test Mean Absolute Error: ", mean_absolute_error(y_test_sc, y_test_sc_pred))
print("Test Mean Squared Error: ", mean_squared_error(y_test_sc, y_test_sc_pred))
print("Test R2 Score: ", r2_score(y_test_sc, y_test_sc_pred))
